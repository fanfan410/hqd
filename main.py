import logging
import pandas as pd
from sklearn.model_selection import train_test_split
from config import *
from data_loader import load_data, explore_data, analyze_missing_values, analyze_target_distribution
from preprocessing import (
    handle_outliers, feature_engineering, create_preprocessor,
    prepare_data_for_model, transform_data, run_preprocessing_steps, analyze_training_data, log_transform_data
)
from model_training import (
    compare_base_models, tune_hyperparameters,
    train_final_model, plot_learning_curve
)
from model_evaluation import generate_evaluation_report
from visualization import create_visualization_report
from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt
import seaborn as sns
import os
import numpy as np
from sklearn.model_selection import GridSearchCV
import warnings
from sklearn.exceptions import ConvergenceWarning
from sklearn.ensemble import GradientBoostingRegressor

# T·∫Øt to√†n b·ªô c·∫£nh b√°o sklearn
warnings.filterwarnings('ignore')
warnings.filterwarnings('ignore', category=ConvergenceWarning)
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)

# Thi·∫øt l·∫≠p logging
logging.basicConfig(
    level=LOG_LEVEL,
    format=LOG_FORMAT,
    handlers=[
        logging.FileHandler(LOG_FILE),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def main():
    """Ch·∫°y to√†n b·ªô pipeline t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi."""
    try:
        # 1. Load v√† kh√°m ph√° d·ªØ li·ªáu
        print("\n=== B∆Ø·ªöC 1: LOAD V√Ä KH√ÅM PH√Å D·ªÆ LI·ªÜU ===")
        logger.info("B·∫Øt ƒë·∫ßu pipeline")
        df = load_data()
        explore_data(df)
        analyze_missing_values(df)
        analyze_target_distribution(df, target_column='SALE_PRC')

        # 2. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu (ƒë·ªìng b·ªô output, ch·ªâ g·ªçi h√†m t·ªïng h·ª£p)
        print("\n=== B∆Ø·ªöC 2: TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU ===")
        logger.info("B·∫Øt ƒë·∫ßu ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")
        df, X_train, X_test, y_train, y_test, numeric_features, categorical_features, preprocessor = run_preprocessing_steps(df)
        # 1.3: Ph√¢n t√≠ch d·ªØ li·ªáu m·∫´u (tr∆∞·ªõc chuy·ªÉn ƒë·ªïi)
        analyze_training_data(X_train, y_train, numeric_features, categorical_features)
        # 1.4: Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu (log transform)
        X_train, X_test, y_train, y_test = log_transform_data(X_train, X_test, y_train, y_test)
        
        # 3. T·∫°o b√°o c√°o tr·ª±c quan h√≥a
        print("\n=== B∆Ø·ªöC 3: T·∫†O B√ÅO C√ÅO TR·ª∞C QUAN H√ìA ===")
        logger.info("T·∫°o b√°o c√°o tr·ª±c quan h√≥a")
        create_visualization_report(
            df, list(numeric_features), list(categorical_features), TARGET_COLUMN
        )
        print("‚úì Ho√†n th√†nh t·∫°o b√°o c√°o tr·ª±c quan h√≥a")
        
        # 4. So s√°nh c√°c m√¥ h√¨nh c∆° b·∫£n
        print("\n=== B∆Ø·ªöC 4: SO S√ÅNH C√ÅC M√î H√åNH C∆† B·∫¢N ===")
        print("ƒêang ch·∫°y cross-validation cho c√°c model... (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)")
        logger.info("So s√°nh c√°c m√¥ h√¨nh c∆° b·∫£n")
        model_comparison_results = compare_base_models(X_train, y_train, preprocessor)
        print("‚úì Ho√†n th√†nh so s√°nh c√°c m√¥ h√¨nh c∆° b·∫£n")
        
        # 5. Tinh ch·ªânh hyperparameters cho m√¥ h√¨nh t·ªët nh·∫•t
        print("\n=== B∆Ø·ªöC 5: TINH CH·ªàNH HYPERPARAMETERS ===")
        print("ƒêang ch·∫°y GridSearchCV... (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)")
        logger.info("Tinh ch·ªânh hyperparameters")
        param_grid = {
            'model__n_estimators': [100, 200],
            'model__max_depth': [3, 5]
        }
        best_model, best_params = tune_hyperparameters(
            X_train, y_train,
            preprocessor, GradientBoostingRegressor(),
            param_grid
        )
        print("‚úì Ho√†n th√†nh tinh ch·ªânh hyperparameters")
        
        # 6. Hu·∫•n luy·ªán m√¥ h√¨nh cu·ªëi c√πng
        print("\n=== B∆Ø·ªöC 6: HU·∫§N LUY·ªÜN M√î H√åNH CU·ªêI C√ôNG ===")
        logger.info("Hu·∫•n luy·ªán m√¥ h√¨nh cu·ªëi c√πng")
        final_model = train_final_model(
            X_train, y_train,
            preprocessor, best_params
        )
        print("‚úì Ho√†n th√†nh hu·∫•n luy·ªán m√¥ h√¨nh cu·ªëi c√πng")
        
        # 7. V·∫Ω learning curve
        print("\n=== B∆Ø·ªöC 7: V·∫º LEARNING CURVE ===")
        logger.info("V·∫Ω learning curve")
        plot_learning_curve(
            final_model, X_train, y_train,
            "Learning Curve c·ªßa M√¥ h√¨nh Cu·ªëi c√πng"
        )
        print("‚úì Ho√†n th√†nh v·∫Ω learning curve")
        
        # 8. ƒê√°nh gi√° m√¥ h√¨nh
        print("\n=== B∆Ø·ªöC 8: ƒê√ÅNH GI√Å M√î H√åNH ===")
        logger.info("ƒê√°nh gi√° m√¥ h√¨nh")
        evaluation_report = generate_evaluation_report(
            final_model, X_test, y_test,
            list(numeric_features) + list(categorical_features)
        )
        print("‚úì Ho√†n th√†nh ƒë√°nh gi√° m√¥ h√¨nh")
        
        print("\nTh·ªëng k√™ bi·∫øn m·ª•c ti√™u (y):")
        print(y.describe())
        
        print("\nTh·ªëng k√™ c√°c bi·∫øn s·ªë:")
        print(X.describe())
        
        print("Danh s√°ch c√°c bi·∫øn ph√¢n lo·∫°i:")
        print(list(categorical_features))
        if not list(categorical_features):
            print("\nKh√¥ng c√≥ bi·∫øn ph√¢n lo·∫°i n√†o trong dataset")
            print("T·∫•t c·∫£ c√°c bi·∫øn ƒë·ªÅu l√† bi·∫øn s·ªë (numeric)")
        
        print("\nüéâ HO√ÄN TH√ÄNH TO√ÄN B·ªò PIPELINE! üéâ")
        logger.info("Ho√†n th√†nh pipeline")
        
    except Exception as e:
        logger.error(f"L·ªói trong pipeline: {str(e)}", exc_info=True)
        raise

def feature_engineering(df):
    """T·∫°o c√°c bi·∫øn m·ªõi t·ª´ d·ªØ li·ªáu hi·ªán c√≥ (ch·ªâ t·∫°o n·∫øu ƒë·ªß c·ªôt)."""
    logger.info("B·∫Øt ƒë·∫ßu t·∫°o bi·∫øn m·ªõi (Feature Engineering)")
    created_features = []

    # 1. Gi√° tr√™n m·ªói feet vu√¥ng ƒë·∫•t
    if 'LND_SQFOOT' in df.columns and 'SALE_PRC' in df.columns:
        df['PRICE_PER_SQFT'] = (df['SALE_PRC'] / df['LND_SQFOOT'].replace(0, np.nan)).fillna(0)
        created_features.append('PRICE_PER_SQFT')

    # 2. T·ª∑ l·ªá di·ªán t√≠ch s·ªëng tr√™n di·ªán t√≠ch ƒë·∫•t
    if 'TOT_LVG_AREA' in df.columns and 'LND_SQFOOT' in df.columns:
        df['LIVING_LAND_RATIO'] = (df['TOT_LVG_AREA'] / df['LND_SQFOOT'].replace(0, np.nan)).fillna(0)
        created_features.append('LIVING_LAND_RATIO')

    # 3. Kho·∫£ng c√°ch trung b√¨nh ƒë·∫øn c√°c ƒëi·ªÉm quan tr·ªçng
    dist_cols = [c for c in ['OCEAN_DIST', 'WATER_DIST', 'CNTR_DIST', 'HWY_DIST'] if c in df.columns]
    if len(dist_cols) > 0:
        df['AVG_IMPORTANT_DIST'] = df[dist_cols].mean(axis=1)
        created_features.append('AVG_IMPORTANT_DIST')

    # V·∫Ω ph√¢n ph·ªëi c·ªßa c√°c bi·∫øn m·ªõi (n·∫øu mu·ªën)
    for feature in created_features:
        try:
            plt.figure(figsize=FIGURE_SIZE)
            sns.histplot(df[feature], kde=True)
            plt.title(f'Ph√¢n ph·ªëi c·ªßa {feature}')
            plt.savefig(os.path.join(PREPROCESSING_VIS_DIR, f'numeric_{feature}_transformation.png'), 
                        dpi=DPI, format=SAVE_FORMAT)
            plt.close()
        except Exception as e:
            logger.error(f"L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì cho {feature}: {str(e)}")

    logger.info(f"ƒê√£ t·∫°o {len(created_features)} bi·∫øn m·ªõi: {', '.join(created_features)}")
    return df, created_features

if __name__ == "__main__":
    main() 